{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading tweets and plotting the quantity of them by month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import  csv\n",
    "import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA='D:\\\\Research\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv(filename, fields=['text', 'svm', 'hand_label', 'posted_time', 'username']):\n",
    "    f = open(filename, 'rb')\n",
    "    csvr = csv.DictReader(f, delimiter=',', quotechar='\"')\n",
    "    for row in csvr:\n",
    "        yield dict([(k, row[k]) for k in fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 4639885 \"all tweets\n"
     ]
    }
   ],
   "source": [
    "#this code saves all tweets to raw_tweets variable\n",
    "raw_tweets = [r for r in read_csv(DATA + 'ecig.csv') ]\n",
    "print 'read', len(raw_tweets), '\"all tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 992633 \"organic\" tweets\n"
     ]
    }
   ],
   "source": [
    "# this code saves just tweets which are tagged as organic to variable organic_tweets\n",
    "\n",
    "organic_tweets = [r for r in read_csv(DATA + 'ecig.csv') if r['svm'] == '-']\n",
    "print 'read', len(organic_tweets), '\"organic\" tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweets by month.\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Input, e.g., 10/1/2012\n",
    "    Output, e.g., 2012-10\"\"\"\n",
    "    parts = datestring.split()\n",
    "    if len(parts) > 1:\n",
    "        datestring = parts[0]\n",
    "        parts = datestring.split('/')\n",
    "        if len(parts) == 3:\n",
    "            s = (parts[2] if len(parts[2]) == 4 else '20' + parts[2]) + \\\n",
    "            '-' + (parts[0] if len(parts[0]) == 2 else '0'+parts[0])\n",
    "            return datetime.datetime.strptime(s, \"%Y-%m\").date()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "def tweets_by_month(all_tweets, organic_tweets):\n",
    "    #parsing date for all_tweets, positive and negative\n",
    "    \n",
    "    months = Counter(parse_date(x['posted_time']) for x in all_tweets)#all\n",
    "    months1 = Counter(parse_date(x1['posted_time']) for x1 in organic_tweets)#organic\n",
    "    \n",
    "    result = Counter((k, v) for k, v in months.iteritems() if k is not None)#all\n",
    "    result1 = Counter((k, v) for k, v in months1.iteritems() if k is not None)#organic\n",
    "    \n",
    "    keys = [f for f in sorted(result.keys())if f is not None]#all\n",
    "    keys1 = [d for d in sorted(result1.keys())if d is not None]#organic\n",
    "    \n",
    "    \n",
    "    values = [r[1] for r in keys]\n",
    "    keys = [r[0] for r in keys]\n",
    "    print 'All tweets', values, '.Total: ',sum(values)\n",
    "\n",
    "    values1 = [r[1] for r in keys1]\n",
    "    keys1 = [r[0] for r in keys1]\n",
    "    print 'Organic tweets', values1, '.Total: ',sum(values1)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    plt.xticks(rotation=70) \n",
    "    ax.xaxis_date()\n",
    "    line, = plt.plot(keys, values, 'bo-')#all\n",
    "    line1, = plt.plot(keys1, values1, 'bo-', color='g')#organic\n",
    "    plt.xlabel('Months')\n",
    "    plt.ylabel('# tweets')\n",
    "    plt.title('Frequency of tweets per month')\n",
    "    plt.legend([line, line1], [\"All tweets\", \"Organic tweets\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets [87190, 179377, 231188, 207418, 614462, 1050127, 487532, 660773, 328882, 262886, 221889, 308158] .Total:  4639882\n",
      "Organic tweets [30026, 36995, 46271, 62883, 65971, 90870, 110735, 84692, 96447, 94180, 114894, 158669] .Total:  992633\n"
     ]
    }
   ],
   "source": [
    "#ploting tweets by month\n",
    "tweets_by_month(raw_tweets, organic_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('D:/Research/file.txt','wb') as fi:\n",
    "#    for r in raw_tweets:\n",
    "#        fi.write(r['posted_time'])\n",
    "#        fi.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#seach for organic tweets and save them in one list\n",
    "tweets=[]\n",
    "with open( DATA +'organic.csv', \"rb\" ) as theFile:\n",
    "    reader = csv.DictReader( theFile )\n",
    "    for row in reader:\n",
    "        tweets.append(row)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nickdrake: C3P0 Enjoys a cigarette break during filming. http://t.co/AVCtEml4 41183.0009143519\n"
     ]
    }
   ],
   "source": [
    "print tweets[1]['text'],tweets[1]['posted_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading all tweets and saving to all_tweets variable\n",
    "all_tweets=[]\n",
    "with open( DATA + 'ecig.csv', \"rb\" ) as theFile:\n",
    "    reader = csv.DictReader( theFile )\n",
    "    for row in reader:\n",
    "        all_tweets.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tweets: 4639885\n"
     ]
    }
   ],
   "source": [
    "print 'Total of tweets:',len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#saving organic tweets in one new file\n",
    "with open( DATA+'organicDef.csv','wb') as organic:\n",
    "    writer = csv.DictWriter(organic, fieldnames=['country_code', 'flag', 'followers_count', 'friends_count', 'hashtag', 'id', 'is_retweet',\n",
    " 'klout_score', 'link', 'location_coord_type', 'location_coords', 'location_displayname', 'location_type', 'media_display_url', 'media_type',\n",
    " 'media_url', 'posted_time', 'real_name', 'rule_match', 'source', 'statuses_count', 'text', 'title', 'tweet_url', 'user_bio_summary',\n",
    " 'user_location', 'user_mention', 'user_mention_username', 'user_twitter_page', 'username', 'shorttime', 'week', 'hand_label', 'svm', 'mdy',\n",
    " '_merge','sent', 'prob_class_1','prob_class_2'])\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in all_tweets:\n",
    "        #row['prob_class_1'] = dasd\n",
    "        if row['svm']== '-':\n",
    "            writer.writerow(row)\n",
    "organic.close()  \n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sampling organic tweets \n",
    "rand_Sample_tweets = random.sample(organic_tweets,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saving sampled organic tweets in one new file\n",
    "with open( DATA+'organicDef.csv','wb') as organic:\n",
    "    writer = csv.DictWriter(organic, fieldnames=['country_code', 'flag', 'followers_count', 'friends_count', 'hashtag', 'id', 'is_retweet',\n",
    " 'klout_score', 'link', 'location_coord_type', 'location_coords', 'location_displayname', 'location_type', 'media_display_url', 'media_type',\n",
    " 'media_url', 'posted_time', 'real_name', 'rule_match', 'source', 'statuses_count', 'text', 'title', 'tweet_url', 'user_bio_summary',\n",
    " 'user_location', 'user_mention', 'user_mention_username', 'user_twitter_page', 'username', 'shorttime', 'week', 'hand_label', 'svm', 'mdy',\n",
    " '_merge','sent','prob_class_1', 'prob_class_2'])\n",
    "    writer.writeheader()\n",
    "    for row in rand_Sample_tweets:\n",
    "        writer.writerow(row)   \n",
    "organic.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading labeled organic tweets and saving them to a list\n",
    "\n",
    "organic_tweets= []\n",
    "\n",
    "with open( DATA+'2000_Sample_3Classes.csv', \"rb\" ) as theFile:\n",
    "    reader = csv.DictReader( theFile )\n",
    "    for row in reader:\n",
    "        organic_tweets.append(row)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 676 positive tweets\n",
      "275 negative tweets\n",
      "1049 negative tweets\n"
     ]
    }
   ],
   "source": [
    "#reading labeled sample of tweets\n",
    "positive_tweets=[]\n",
    "negative_tweets=[]\n",
    "other_tweets=[]\n",
    "with open( DATA+'2000_Sample_3Classes.csv', \"rb\" ) as theFile:\n",
    "    reader = csv.DictReader( theFile )\n",
    "    for row in reader:\n",
    "        if row['sent']== '1':\n",
    "            #print row['text']\n",
    "            positive_tweets.append(row)\n",
    "        elif row['sent']== '-1':\n",
    "            #print row['text']\n",
    "            negative_tweets.append(row) \n",
    "        else:\n",
    "            other_tweets.append(row) \n",
    "        \n",
    "            \n",
    "print 'We have', len(positive_tweets), 'positive tweets'\n",
    "print  len(negative_tweets), 'negative tweets'\n",
    "print  len(other_tweets), 'negative tweets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sampling new 200 tweets to double check accuracy of classifier\n",
    "\n",
    "rand_Sample_200tweets = random.sample(organic_tweets,200)\n",
    "\n",
    "with open( DATA+'organicTweetsSample200.csv','wb') as organic_200:\n",
    "    writer = csv.DictWriter(organic_200, fieldnames=['country_code', 'flag', 'followers_count', 'friends_count', 'hashtag', 'id', 'is_retweet',\n",
    " 'klout_score', 'link', 'location_coord_type', 'location_coords', 'location_displayname', 'location_type', 'media_display_url', 'media_type',\n",
    " 'media_url', 'posted_time', 'real_name', 'rule_match', 'source', 'statuses_count', 'text', 'title', 'tweet_url', 'user_bio_summary',\n",
    " 'user_location', 'user_mention', 'user_mention_username', 'user_twitter_page', 'username', 'shorttime', 'week', 'hand_label', 'svm', 'mdy',\n",
    " '_merge','sent','prob_class_1', 'prob_class_2'])\n",
    "    writer.writeheader()\n",
    "    for row in rand_Sample_200tweets:\n",
    "        writer.writerow(row)   \n",
    "organic.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
