{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all code to reproduce results in the paper \"Analyzing e-cigarette sentiment of Twitter\", published in the Computational Health Sciences Workshop at the 6th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with the data collected by Sherry Emery et al. <slemery@uic.edu>, which consists 4.6M tweets from 2012-10-01 to 2013-09-30. These tweets have already been classified as \"organic\" or not using an SVM classifier (see Huang, Jidong et al. \"A cross-sectional examination of marketing of electronic cigarettes on Twitter.\" Tobacco control). We restrict our analysis to those classified as organic. We will assume these data live in `/data/chs15/ecig.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import cPickle\n",
    "import csv\n",
    "import datetime\n",
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tabulate import tabulate\n",
    "\n",
    "DATA = '/data/chs15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename, fields=['text', 'svm', 'hand_label', 'posted_time', 'real_name', 'username']):\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    csvr = csv.DictReader(f, delimiter=',', quotechar='\"')\n",
    "    for row in csvr:\n",
    "        yield dict([(k, row[k]) for k in fields if k in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 992633 \"organic\" tweets\n"
     ]
    }
   ],
   "source": [
    "# Read all \"organic\" tweets.\n",
    "raw_tweets = [r for r in read_csv(DATA + '/ecig.csv.gz') if r['svm'] == '-']\n",
    "print('read %d \"organic\" tweets' % len(raw_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we manually lableed 2,000 tweets into one of three categories:\n",
    "- **positive (1):** express positive sentiment toward ecigs, or indicate that the speaker uses ecigs.\n",
    "- **negative (-1):** express negative sentiment toward ecigs\n",
    "- **neutral (0):** do not express sentiment, e.g., informative\n",
    "\n",
    "We assume these data live in `/data/chs15/labeled.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2000 labeled tweets\n",
      "Label distribution=[('neutral', 1014), ('positive', 704), ('negative', 282)]\n"
     ]
    }
   ],
   "source": [
    "labeled_tweets = [r for r in read_csv(DATA + '/labeled.csv.gz', fields=['text', 'sent', 'real_name', 'username'])]\n",
    "\n",
    "print('read %d labeled tweets' % len(labeled_tweets))\n",
    "# Set labels.\n",
    "\n",
    "label_map = {'-1': 'negative', '0': 'neutral', '1': 'positive'}\n",
    "for t in labeled_tweets:\n",
    "    t['sent'] = label_map[t['sent']]\n",
    "             \n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['negative', 'neutral', 'positive'])\n",
    "y = label_encoder.transform([t['sent'] for t in labeled_tweets])             \n",
    "print('Label distribution=%s' % Counter(t['sent'] for t in labeled_tweets).most_common(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `labeled_tweets`, we'll train a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tweet tokenizer.\n",
    "def tokenize(text):\n",
    "    punc_re = '[' + re.escape(string.punctuation) + ']'\n",
    "    text = text.lower()\n",
    "    text = re.sub('#(\\S+)', r'HASHTAG_\\1', text)\n",
    "    text = re.sub('@(\\S+)', r'MENTION_\\1', text)\n",
    "    text = re.sub('http\\S+', 'THIS_IS_A_URL', text)\n",
    "    text = re.sub(r'(.)\\1\\1\\1+', r'\\1', text)\n",
    "    text = re.sub(r'[0-9]', '9', text)\n",
    "    toks = []\n",
    "    for tok in text.split():\n",
    "        tok = re.sub(r'^(' + punc_re + '+)', r'\\1 ', tok)\n",
    "        tok = re.sub(r'(' + punc_re + '+)$', r' \\1', tok)\n",
    "        for subtok in tok.split():\n",
    "            if re.search('\\w', subtok):\n",
    "                toks.append(subtok)\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized 2000 tweets. Found 4824 terms.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', ngram_range=(1, 2), max_df=1., min_df=2,\n",
    "                             use_idf=True, tokenizer=tokenize, binary=False, norm='l2')\n",
    "X = vectorizer.fit_transform(t['text'] for t in labeled_tweets)\n",
    "print('Vectorized %d tweets. Found %d terms.' % (X_labeled.shape[0], X.shape[1]))\n",
    "features = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.744\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.60      0.54      0.57       282\n",
      "    neutral       0.77      0.84      0.81      1014\n",
      "   positive       0.75      0.68      0.71       704\n",
      "\n",
      "avg / total       0.74      0.74      0.74      2000\n",
      "\n",
      "            negative    neutral    positive\n",
      "--------  ----------  ---------  ----------\n",
      "negative         152         68          62\n",
      "neutral           59        856          99\n",
      "positive          43        182         479\n",
      "\n",
      "CLASS 0\n",
      "you\t2.542\n",
      "smoking\t2.334\n",
      "smoking an\t2.254\n",
      "he\t2.107\n",
      "fuck\t2.010\n",
      "people\t1.902\n",
      "smokes\t1.833\n",
      "an\t1.816\n",
      "faggot\t1.791\n",
      "are\t1.783\n",
      "class\t1.753\n",
      "smoke\t1.736\n",
      "stupid\t1.724\n",
      "in\t1.527\n",
      "look\t1.504\n",
      "shit\t1.473\n",
      "her\t1.402\n",
      "pussy\t1.383\n",
      "sorry\t1.342\n",
      "one\t1.320\n",
      "\n",
      "CLASS 1\n",
      "THIS_IS_A_URL\t5.085\n",
      "e-cigarettes\t1.661\n",
      "de\t1.345\n",
      "la\t1.170\n",
      "99\t1.167\n",
      "retail\t1.052\n",
      "THIS_IS_A_URL retail\t1.052\n",
      "ni\t0.988\n",
      "e-cigarette\t0.942\n",
      "markten\t0.932\n",
      "store\t0.931\n",
      "by\t0.894\n",
      "cigarette\t0.883\n",
      "of\t0.876\n",
      "dallas\t0.862\n",
      "smokers\t0.801\n",
      "9999\t0.770\n",
      "MENTION_vaper_trail\t0.763\n",
      "electronic\t0.724\n",
      "may\t0.712\n",
      "\n",
      "CLASS 2\n",
      "my\t5.273\n",
      "i\t4.459\n",
      "vaping\t1.901\n",
      "HASHTAG_vaping\t1.592\n",
      "HASHTAG_ecig\t1.456\n",
      "my ecig\t1.356\n",
      "me\t1.306\n",
      "we\t1.242\n",
      "HASHTAG_vape\t1.241\n",
      "got\t1.229\n",
      "e-cig\t1.213\n",
      "my e-cig\t1.180\n",
      "HASHTAG_euecigban\t1.155\n",
      "my e\t1.087\n",
      "vape\t1.085\n",
      "i'm\t1.084\n",
      "good\t0.960\n",
      "this\t0.925\n",
      "i need\t0.905\n",
      "to black\t0.899\n"
     ]
    }
   ],
   "source": [
    "def confusion(truths, preds, labels):\n",
    "    m = confusion_matrix(truths, preds)\n",
    "    m = np.vstack((labels, m))\n",
    "    m = np.hstack((np.matrix([''] + list(labels)).T, m))\n",
    "    return tabulate(m.tolist(), headers='firstrow')\n",
    "\n",
    "def top_coef(clf, vocab, n=10):\n",
    "    if len(clf.classes_) == 2:\n",
    "        coefs = [clf.coef_[0], -clf.coef_[0]]\n",
    "    else:\n",
    "        coefs = clf.coef_\n",
    "    for li, label in enumerate(clf.classes_):\n",
    "        print('\\nCLASS %s' % label)\n",
    "        coef = coefs[li]\n",
    "        top_coef_ind = np.argsort(coef)[::-1][:n]\n",
    "        top_coef_terms = vocab[top_coef_ind]\n",
    "        top_coef = coef[top_coef_ind]\n",
    "        print '\\n'.join(['%s\\t%.3f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)])\n",
    "\n",
    "def do_cv(X, y, labels, nfolds=10):\n",
    "    cv = KFold(len(y), nfolds, random_state=123456)\n",
    "    preds = []\n",
    "    truths = []\n",
    "    for train, test in cv:\n",
    "        clf = LogisticRegression(class_weight='auto')\n",
    "        clf.fit(X[train], y[train])\n",
    "        preds.extend(clf.predict(X[test]))\n",
    "        truths.extend(y[test])\n",
    "    print ('accuracy=%.3f' % (accuracy_score(truths, preds)))\n",
    "    print classification_report(truths, preds, target_names=labels)\n",
    "    print confusion(truths, preds, labels)\n",
    "    clf = LogisticRegression(class_weight='auto')\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "clf = do_cv(X, y, label_encoder.classes_, 10)\n",
    "top_coef(clf, features, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.810\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.80      0.82      0.81       986\n",
      "   positive       0.82      0.80      0.81      1014\n",
      "\n",
      "avg / total       0.81      0.81      0.81      2000\n",
      "\n",
      "            negative    positive\n",
      "--------  ----------  ----------\n",
      "negative         812         174\n",
      "positive         206         808\n",
      "\n",
      "CLASS 0\n",
      "THIS_IS_A_URL\t5.721\n",
      "e-cigarettes\t1.803\n",
      "de\t1.487\n",
      "99\t1.337\n",
      "la\t1.334\n",
      "ni\t1.208\n",
      "THIS_IS_A_URL retail\t1.194\n",
      "retail\t1.194\n",
      "of\t1.150\n",
      "by\t1.104\n",
      "cigarette\t1.097\n",
      "store\t1.089\n",
      "markten\t1.061\n",
      "e-cigarette\t1.026\n",
      "smokers\t0.999\n",
      "dallas\t0.985\n",
      "9999\t0.918\n",
      "MENTION_vaper_trail\t0.912\n",
      "vuse\t0.894\n",
      "may\t0.887\n",
      "\n",
      "CLASS 1\n",
      "my\t4.881\n",
      "i\t4.049\n",
      "an\t2.154\n",
      "smoking\t1.904\n",
      "vaping\t1.702\n",
      "lol\t1.505\n",
      "got\t1.427\n",
      "fuck\t1.381\n",
      "me\t1.321\n",
      "HASHTAG_vaping\t1.309\n",
      "class\t1.297\n",
      "this\t1.261\n",
      "e-cig\t1.218\n",
      "shit\t1.133\n",
      "HASHTAG_ecig\t1.131\n",
      "cool\t1.104\n",
      "HASHTAG_vape\t1.101\n",
      "i'm\t1.079\n",
      "my ecig\t1.017\n",
      "smoking an\t1.006\n"
     ]
    }
   ],
   "source": [
    "# Also try collapsing classes -1 and 0.\n",
    "y_collapsed = np.array([1 if yi == 1 else 0 for yi in y])\n",
    "labels_collapsed = ['negative', 'positive']\n",
    "clf_collapsed = do_cv(X, y_collapsed, labels_collapsed, 10)\n",
    "top_coef(clf_collapsed, features, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the superior accuracy of the collapsed classifier, we'll proceed by collapsing 'negative' and 'neutral' into one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clf_collapsed\n",
    "labels = labels_collapsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "name": "python",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
