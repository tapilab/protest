{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io, os, glob\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR1='/home/elaine/protest/DATA/Timeline/all timeline/'\n",
    "DIR2='/home/elaine/protest/DATA/mentions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parse date \n",
    "def parse_date(datestring):\n",
    "    \"\"\" Input, e.g., Mon Aug 24 19:41:14 +0000 2015\n",
    "    Output, e.g., 24 \"\"\"\n",
    "    #Sat May 16 16:30:12 +0000 2015\n",
    "    #print datestring\n",
    "    parts = datestring.split()\n",
    "    var = datetime.strptime(parts[1]+' ' +parts[2]+' '+ parts[5],'%b %d %Y')\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file = open('all_mentions_graph.pkl', 'rb')#open pickle file where the edges of the graph is saved\n",
    "data1 = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "for _, _, arquivos in os.walk(DIR2): arquivos#list of all files in the directory\n",
    "dic = defaultdict(float)    \n",
    "count=0    \n",
    "\n",
    "for file in glob.glob(DIR1+'*.txt'):  #loops through files in the directory\n",
    "    with io.open(file,'r',encoding=\"utf-8\") as f:#opens each file\n",
    "        print(file)   \n",
    "        file_users = f.readlines()\n",
    "        for f in file_users:  #reads each line of the file\n",
    "            tweet = json.loads(f) #each tweet\n",
    "            if data1.has_node(tweet['user']['screen_name'].replace('.txt',\"\")) == True: #if that file is in the graph \n",
    "                #if that tweet has one of the keywords\n",
    "                if 'foraDILMA' in tweet['text'] or 'foradilma' in tweet['text'] or 'Fora Dilma' in tweet['text'] or 'foraDilma' in tweet['text'] or 'FORADILMA' in tweet['text'] or 'fora Dilma' in tweet['text'] or 'FORA DILMA' in tweet['text'] or 'ForaDilma' in tweet['text'] or'foraPT' in tweet['text'] or 'FORAPT' in tweet['text'] or 'fora pt' in tweet['text']or 'FORA PT' in tweet['text'] or 'ForaPT' in tweet['text'] or'vempraRua' in tweet['text'] or 'vemprarua' in tweet['text'] or 'vem pra rua' in tweet['text']or 'VEMPRARUA' in tweet['text'] or 'VemPraRua' in tweet['text']:\n",
    "                    date = tweet['created_at'] #save date - at time T\n",
    "                    neighbors = data1.neighbors(tweet['user']['screen_name']) #get all neighbors of the user\n",
    "                    #print len(neighbors)\n",
    "                    #print neighbors\n",
    "                    for n in neighbors:#loop through each neighbor and counts if the neighbor's tweet has also one of the keywords\n",
    "                        if n+'.txt' in arquivos:#if that file is in the directory\n",
    "                            neighbor = open(DIR2+n+'.txt','r')\n",
    "                            teste = neighbor.readlines()\n",
    "                            for t in teste:\n",
    "                                tweet2 = json.loads(t)\n",
    "                                \n",
    "                                if parse_date(tweet2['created_at'])< parse_date(date):\n",
    "                                    \n",
    "                                    if 'foraDILMA' in tweet2['text'] or 'foradilma' in tweet2['text'] or 'Fora Dilma' in tweet2['text'] or 'foraDilma' in tweet2['text'] or 'FORADILMA' in tweet2['text'] or 'fora Dilma' in tweet2['text'] or 'FORA DILMA' in tweet2['text'] or 'ForaDilma' in tweet2['text'] or'foraPT' in tweet2['text'] or 'FORAPT' in tweet2['text'] or 'fora pt' in tweet2['text']or 'FORA PT' in tweet2['text'] or 'ForaPT' in tweet2['text'] or'vempraRua' in tweet2['text'] or 'vemprarua' in tweet2['text'] or 'vem pra rua' in tweet2['text']or 'VEMPRARUA' in tweet2['text'] or 'VemPraRua' in tweet2['text']:\n",
    "                                        #print parse_date(tweet2['created_at']),'<', parse_date(date)\n",
    "                                        #print tweet2['user']['screen_name'], tweet2['text']\n",
    "                                        count=count+1\n",
    "                                        break\n",
    "                    #print 'count:',count\n",
    "                    #print float(count),'/',float(len(neighbors))\n",
    "                    dic[tweet['user']['screen_name']]=float(count)/float(len(neighbors))\n",
    "                    #print dic[tweet['user']['screen_name']]\n",
    "                    count=0\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = open('neighbors_hashtag_use.pkl', 'wb')\n",
    "pickle.dump(dic, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyunpack import Archive\n",
    "#Archive('a.zip').extractall('/path/to')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
