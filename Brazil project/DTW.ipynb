{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example using Dynamic Time Warping for clustering. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l2(xi, yi):\n",
    "    return (xi - yi)**2\n",
    "\n",
    "def dtw_fn(x, y):\n",
    "    \"\"\" Compute dynamic time warping distances for two time series x and y.\"\"\"\n",
    "    r, c = len(x), len(y)\n",
    "    max_window = 10 # max search window (smaller->more efficient but less exact)\n",
    "    w = max(max_window, abs(r - c))  \n",
    "    D = np.ones((r + 1, c + 1)) * np.inf\n",
    "    D[0, 0] = 0.\n",
    "\n",
    "    for i in range(r):\n",
    "        for j in range(max(0, i - w), min(c, i + w)):\n",
    "            D[i+1, j+1] = l2(x[i], y[j])\n",
    "\n",
    "    for i in range(r):  # why loop twice?!!\n",
    "        for j in range(max(0, i - w), min(c, i + w)):\n",
    "            D[i+1, j+1] += min(D[i, j], D[i, j+1], D[i+1, j])\n",
    "\n",
    "    D = D[1:, 1:]\n",
    "    return math.sqrt(D[-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example.\n",
    "dtw_fn([0,2,1,1.5], [0,0,2,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dtw(X):\n",
    "    \"\"\" Compute dtw for all pairs of rows in a matrix.\"\"\"\n",
    "    distances = np.zeros((len(X), len(X)))\n",
    "    for i, j in combinations(range(len(X)), 2):\n",
    "        distances[i,j] = dtw_fzn(X[i], X[j])\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample data.\n",
    "X = np.array([[0,1,2,3], [1,2,3,0,2], [1,2,3],\n",
    "              [5,0,5,0,5], [5,0,5,0,5,5], [5,0,5,0,4],\n",
    "              [6,6,6], [6,6,6,7], [1, 0, 6, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  2.,  3.],\n",
       "       [ 0.,  1.,  2.,  3.,  0.,  2.],\n",
       "       [ 0.,  0.,  0.,  1.,  2.,  3.],\n",
       "       [ 0.,  5.,  0.,  5.,  0.,  5.],\n",
       "       [ 5.,  0.,  5.,  0.,  5.,  5.],\n",
       "       [ 0.,  5.,  0.,  5.,  0.,  4.],\n",
       "       [ 0.,  0.,  0.,  6.,  6.,  6.],\n",
       "       [ 0.,  0.,  6.,  6.,  6.,  7.],\n",
       "       [ 0.,  0.,  1.,  0.,  6.,  6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad each row with leading zeros to make all have same length.\n",
    "def pad_data(X):\n",
    "    max_len = max(len(i) for i in X)\n",
    "    Xnew = np.zeros((len(X), max_len))\n",
    "    for i, row in enumerate(X):\n",
    "        diff = max_len - len(row)\n",
    "        if diff > 0:\n",
    "            Xnew[i] = np.concatenate(([0] * (diff), row))\n",
    "        else:\n",
    "            Xnew[i] = row\n",
    "    return Xnew\n",
    "X = pad_data(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster into 3 clusters using DTW.\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clusterer = AgglomerativeClustering(n_clusters=3, affinity=dtw, linkage='average')\n",
    "clusters = clusterer.fit_predict(X)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3, 1: 6, 2: 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_centroids(X, clusters):\n",
    "    \"\"\"Find the centroid of each cluster, defined as the cluster element that\n",
    "    has the lowest distance to all other elements in the cluster. \"\"\"\n",
    "    clusterids = set(clusters)\n",
    "    cluster2centroid = dict()\n",
    "    for clusterid in clusterids:\n",
    "        cluster = np.where(clusters == clusterid)[0]\n",
    "        distances = dtw(X[cluster])\n",
    "        centroid = cluster[np.argmin(row.sum() for row in distances)]\n",
    "        cluster2centroid[clusterid] = centroid\n",
    "    return cluster2centroid\n",
    "cluster2centroid = find_centroids(X, clusters)\n",
    "cluster2centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "DIR= '/home/elaine/Protest/protest/Brazil project/'\n",
    "pkl_file = open(DIR+'dictionaryofresults.pkl', 'rb')#open pickle file where the edges of the graph is saved\n",
    "data1 = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar=[]\n",
    "for k, v in data1.items():\n",
    "    ar.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new=pad_data(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = dtw(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster2centroid = find_centroids(new, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 57, 2: 156}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster2centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 57, 156])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster2centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
